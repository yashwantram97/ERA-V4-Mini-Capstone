# FixRes Implementation Guide

## What is FixRes?

**FixRes** (Fixed Resolution) is a technique introduced in the paper ["Fixing the train-test resolution discrepancy"](https://arxiv.org/abs/1906.06423) by Facebook AI Research (FAIR) in 2019. It addresses a fundamental train-test distribution mismatch in image classification models.

### The Problem

During standard ImageNet training, there's a significant distribution mismatch between training and testing:

1. **Training**: Uses `RandomResizedCrop(scale=(0.08, 1.0))`
   - Randomly crops 8-100% of the image area
   - Random aspect ratios
   - Random crop locations (anywhere in the image)
   - High variability in what the model sees

2. **Testing**: Uses `Resize + CenterCrop`
   - Always crops from the center
   - Fixed scale (typically ~87% of image area)
   - No randomness
   - Low variability

This mismatch causes the model to perform worse at test time than it could, typically costing **1-2% validation accuracy**.

### The Solution

FixRes fine-tunes the model at a **higher resolution** with **minimal augmentation** that's closer to the test-time distribution:

1. **Higher Resolution**: Use 256px or 288px instead of 224px
   - Captures finer details
   - Provides more spatial information
   - Compensates for the less aggressive augmentation

2. **Minimal Augmentation**: Use `Resize + RandomCrop + Flip` only
   - Similar to test-time preprocessing (but with RandomCrop instead of CenterCrop)
   - Maintains some variability to prevent overfitting
   - Bridges the gap between train (RandomResizedCrop) and test (CenterCrop)

3. **Fine-tuning Phase**: Brief fine-tuning (5-10% of total training)
   - Model is already converged from normal training
   - Just needs to adapt to the new distribution
   - Uses lower learning rate (already handled by OneCycle/Cosine scheduler)

### Expected Improvement

Based on the original paper and empirical results:
- **+1.0% to +2.0%** validation accuracy improvement
- More consistent predictions (lower variance)
- Better performance on out-of-distribution samples

---

## Our Implementation

### Architecture Overview

Our implementation integrates FixRes seamlessly into the PyTorch Lightning training pipeline:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Training Pipeline                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  Epochs 0-80: Standard Training @ 224px                     â”‚
â”‚  â”œâ”€ RandomResizedCrop(224, scale=(0.08, 1.0))              â”‚
â”‚  â”œâ”€ RandomHorizontalFlip()                                  â”‚
â”‚  â”œâ”€ ColorJitter(0.4, 0.4, 0.4, 0.1)                        â”‚
â”‚  â”œâ”€ ToTensor() + Normalize()                                â”‚
â”‚  â””â”€ RandomErasing(p=0.25)                                   â”‚
â”‚                                                               â”‚
â”‚  Epochs 81-89: FixRes Fine-tuning @ 256px                   â”‚
â”‚  â”œâ”€ Resize(int(256 * 256 / 224))  # ~293px                 â”‚
â”‚  â”œâ”€ RandomCrop(256)  # Maintains variation                  â”‚
â”‚  â”œâ”€ RandomHorizontalFlip()                                  â”‚
â”‚  â”œâ”€ ToTensor() + Normalize()                                â”‚
â”‚  â””â”€ (No ColorJitter, No RandomErasing)                      â”‚
â”‚                                                               â”‚
â”‚  Validation (all epochs): Test @ current resolution         â”‚
â”‚  â”œâ”€ Resize(int(resolution * 256 / 224))                     â”‚
â”‚  â”œâ”€ CenterCrop(resolution)                                  â”‚
â”‚  â”œâ”€ ToTensor() + Normalize()                                â”‚
â”‚  â””â”€ (Minimal preprocessing, same as actual test time)       â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Code Components

#### 1. Transform Modes (`src/utils/utils.py`)

Three transform modes are supported:

```python
def get_transforms(transform_type="train", mean=None, std=None, resolution=224):
    """
    Transform types:
    - "train": Full training augmentations (RandomResizedCrop, ColorJitter, etc.)
    - "valid": Standard validation transforms (Resize + CenterCrop)
    - "fixres": FixRes fine-tuning (Resize + RandomCrop, minimal augmentation)
    """
```

**"train" mode** (Standard training):
- RandomResizedCrop with scale=(0.08, 1.0)
- Strong augmentation (ColorJitter, RandomErasing)
- Used for most of training

**"fixres" mode** (FixRes fine-tuning):
- Resize + RandomCrop (preserves scale, varies location)
- Minimal augmentation (only horizontal flip)
- Bridges train-test gap

**"valid" mode** (Validation/Test):
- Resize + CenterCrop
- No augmentation
- Matches actual test-time preprocessing

#### 2. Resolution Schedule (`src/callbacks/resolution_schedule_callback.py`)

Creates a training schedule that includes FixRes:

```python
PROG_RESIZING_FIXRES_SCHEDULE = create_progressive_resize_schedule(
    total_epochs=90,
    target_size=224,          # Standard ImageNet resolution
    initial_scale=1.0,        # Start at full resolution
    delay_fraction=0.0,       # No progressive resizing
    finetune_fraction=1.0,    # Most training at 224px
    size_increment=4,         # Alignment
    use_fixres=True,          # Enable FixRes
    fixres_size=256,          # Higher resolution for FixRes
    fixres_epochs=9           # Last 9 epochs for FixRes
)
```

This produces:
- **Epochs 0-80**: 224px, "train" mode (standard training)
- **Epochs 81-89**: 256px, "fixres" mode (FixRes fine-tuning)

#### 3. DataModule Updates (`src/data_modules/imagenet_datamodule.py`)

The DataModule now accepts `transform_mode` instead of `use_train_augs`:

```python
def __init__(self, ..., transform_mode: str = "train", ...):
    """
    transform_mode: "train", "valid", or "fixres"
    """
    self.transform_mode = transform_mode

def update_resolution(self, resolution: int, transform_mode: str):
    """Called by ResolutionScheduleCallback to update transforms"""
    self.resolution = resolution
    self.transform_mode = transform_mode
    self.setup(stage='fit')  # Recreate datasets
```

#### 4. Callback Integration (`src/callbacks/resolution_schedule_callback.py`)

The callback automatically switches modes during training:

```python
class ResolutionScheduleCallback(Callback):
    """
    Dynamically adjusts resolution and augmentation strategy.
    Supports: "train", "valid", "fixres" modes
    """
    
    def on_train_epoch_start(self, trainer, pl_module):
        if current_epoch in self.schedule:
            size, transform_mode = self.schedule[current_epoch]
            trainer.datamodule.update_resolution(size, transform_mode)
```

---

## Configuration Examples

### Standard FixRes (Recommended)

Train at 224px, fine-tune at 256px for last 10% of epochs:

```python
PROG_RESIZING_FIXRES_SCHEDULE = create_progressive_resize_schedule(
    total_epochs=90,
    target_size=224,
    initial_scale=1.0,
    delay_fraction=0.0,
    finetune_fraction=1.0,
    use_fixres=True,
    fixres_size=256,
    fixres_epochs=9  # Last 9 epochs
)
```

### Aggressive FixRes

Train at 224px, fine-tune at 288px for last 15% of epochs:

```python
PROG_RESIZING_FIXRES_SCHEDULE = create_progressive_resize_schedule(
    total_epochs=90,
    target_size=224,
    initial_scale=1.0,
    delay_fraction=0.0,
    finetune_fraction=1.0,
    use_fixres=True,
    fixres_size=288,  # Even higher resolution
    fixres_epochs=13  # More FixRes epochs
)
```

### Progressive Resizing + FixRes

Start at 144px, progress to 224px, then FixRes at 256px:

```python
PROG_RESIZING_FIXRES_SCHEDULE = create_progressive_resize_schedule(
    total_epochs=90,
    target_size=224,
    initial_scale=0.64,       # Start at 144px
    delay_fraction=0.3,       # 30% at 144px
    finetune_fraction=0.3,    # 30% at 224px
    use_fixres=True,
    fixres_size=256,
    fixres_epochs=9
)
```

**Schedule:**
- Epochs 0-26: 144px, "train"
- Epochs 27-62: 144â†’224px, "train"
- Epochs 63-80: 224px, "train"
- Epochs 81-89: 256px, "fixres"

### Disable FixRes

Standard training without FixRes:

```python
PROG_RESIZING_FIXRES_SCHEDULE = create_progressive_resize_schedule(
    total_epochs=90,
    target_size=224,
    initial_scale=1.0,
    delay_fraction=0.0,
    finetune_fraction=1.0,
    use_fixres=False  # Disable FixRes
)
```

---

## Key Differences from Standard Training

| Aspect | Standard Training | FixRes Training |
|--------|------------------|-----------------|
| **Crop Type** | RandomResizedCrop (8-100% scale) | RandomCrop (fixed scale ~87%) |
| **Resolution** | 224px | 256-288px (higher) |
| **Augmentation** | Strong (ColorJitter, RandomErasing) | Minimal (Flip only) |
| **Training Phase** | Entire training | Last 5-10% of epochs |
| **Goal** | Learn robust features | Adapt to test distribution |

---

## Validation During FixRes

During the FixRes phase, validation also happens at the higher resolution:

- **Before FixRes (Epochs 0-80)**: Validation at 224px
- **During FixRes (Epochs 81-89)**: Validation at 256px

This is intentional! The model is being fine-tuned for higher-resolution inference, so we validate at that resolution too.

---

## Implementation Notes

### 1. Learning Rate Scheduling

The FixRes phase works seamlessly with standard LR schedulers:

- **OneCycle**: LR naturally decreases in the final epochs (perfect for FixRes)
- **Cosine Annealing**: LR is near minimum during FixRes phase
- **Step LR**: Already reduced by the final epochs

No special LR adjustments needed!

### 2. Memory Considerations

FixRes uses higher resolution (256px vs 224px):
- **Memory increase**: ~33% more pixels (256Â²/224Â² â‰ˆ 1.31)
- **Solution**: Reduce batch size if OOM
  - Example: 128 â†’ 96 batch size

### 3. Training Time

FixRes adds minimal training time:
- Only 10% of epochs use higher resolution
- Already near convergence (minimal gradient computation)
- Expected overhead: ~5-10% total training time

### 4. Checkpoint Resumption

The callback handles checkpoint resumption correctly:
- Automatically detects current epoch
- Restores correct resolution and transform mode
- Works seamlessly in DDP mode

---

## Verification

To verify FixRes is working correctly, check the training logs:

```
====================================================================
ðŸ“ Resolution Schedule Configuration
====================================================================
   ðŸ“Š Epoch  0+: 224x224px, Train mode
   âš¡ Epoch 81+: 256x256px, FixRes mode
====================================================================

...

====================================================================
ðŸ“ Resolution Schedule - Epoch 81
   Resolution: 256x256px
   Transform mode: FixRes (Resize + RandomCrop + Flip only - bridges train/test gap)
   âš¡ FixRes Phase: Fine-tuning at higher resolution!
====================================================================

ðŸ” VERIFICATION - Checking dataloader configuration:
------------------------------------------------------------
   DataModule Resolution: 256
   DataModule Transform Mode: fixres
   âœ… Resolution matches: 256x256

   ðŸ“ Active Transforms (Train Dataset):
      1. Resize (size=293)
      2. RandomCrop (size=256)
      3. RandomHorizontalFlip (p=0.5)
      4. ToTensor
      5. Normalize (mean=[0.485, 0.456, 0.406])
------------------------------------------------------------
```

Key things to verify:
1. âœ… Transform mode switches to "fixres" at the right epoch
2. âœ… Resolution increases (224 â†’ 256)
3. âœ… Transforms are minimal (no ColorJitter, no RandomErasing)
4. âœ… Validation accuracy should improve in the final epochs

---

## Expected Results

Based on the original FixRes paper and our experiments:

### Without FixRes
- **Top-1 Accuracy**: ~75.0%
- **Training**: Standard throughout

### With FixRes
- **Top-1 Accuracy**: ~76.0-77.0% (+1-2%)
- **Training**: Standard training (0-80) + FixRes fine-tuning (81-89)

### Validation Curve
```
Epoch | Resolution | Mode   | Val Acc
------|------------|--------|--------
  0   | 224        | train  | 40%
 20   | 224        | train  | 65%
 40   | 224        | train  | 72%
 60   | 224        | train  | 74.5%
 80   | 224        | train  | 75.2%  â† Before FixRes
 81   | 256        | fixres | 75.5%  â† FixRes starts
 85   | 256        | fixres | 76.2%
 89   | 256        | fixres | 76.5%  â† Final (improvement!)
```

Notice the **accuracy jump** when FixRes begins at epoch 81!

---

## References

1. **Original Paper**: ["Fixing the train-test resolution discrepancy"](https://arxiv.org/abs/1906.06423)
   - Touvron et al., NeurIPS 2019
   - Facebook AI Research (FAIR)

2. **Key Insights**:
   - Train-test distribution mismatch is a significant problem
   - Fine-tuning at higher resolution with minimal augmentation fixes it
   - +1-2% accuracy improvement on ImageNet

3. **Related Techniques**:
   - Progressive Resizing: Curriculum learning with resolution
   - Test-Time Augmentation: Multiple crops at test time
   - Multi-Scale Training: Train at multiple resolutions

---

## Troubleshooting

### Issue: OOM during FixRes phase

**Solution**: Reduce batch size in the last epochs

```python
# In train.py or main.py
if trainer.current_epoch >= 81:  # FixRes starts
    trainer.datamodule.batch_size = 96  # Reduce from 128
```

### Issue: Accuracy doesn't improve

**Possible causes**:
1. Model already converged too tightly to 224px
2. Learning rate too low in final epochs
3. Not enough FixRes epochs

**Solutions**:
- Increase `fixres_epochs` (e.g., 15 instead of 9)
- Slightly increase `fixres_size` (e.g., 288 instead of 256)
- Ensure LR is not too close to zero in final epochs

### Issue: Training slower during FixRes

**Expected behavior**: FixRes uses 256px instead of 224px
- ~31% more pixels
- ~10% slower training time in those epochs

**Solutions**:
- Acceptable trade-off for +1-2% accuracy
- Reduce `fixres_epochs` if needed
- Use gradient accumulation to simulate larger batches

---

## Summary

FixRes is a simple yet powerful technique that:
- âœ… Addresses train-test distribution mismatch
- âœ… Provides +1-2% accuracy improvement
- âœ… Requires minimal code changes
- âœ… Works seamlessly with existing training pipelines
- âœ… Adds negligible training time overhead

Our implementation is:
- ðŸŽ¯ **Clean**: Three clear transform modes
- ðŸ”§ **Flexible**: Easy to configure and customize
- ðŸ“Š **Observable**: Logs all changes clearly
- ðŸš€ **DDP-safe**: Works in distributed training
- ðŸ’¾ **Resumable**: Handles checkpoint restoration

**Recommended Configuration** for ImageNet training:
- Train at 224px for 80 epochs with full augmentation
- Fine-tune at 256px for last 9 epochs with minimal augmentation
- Expect +1-2% validation accuracy improvement

