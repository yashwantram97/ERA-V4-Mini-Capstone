{
  "experiment_info": {
    "experiment_name": "imagenet_p3_training",
    "timestamp": "2025-11-02T03:05:17.349610",
    "duration_seconds": 7780.049151420593,
    "duration_minutes": 129.6674858570099,
    "total_epochs": 90
  },
  "metrics": {
    "val": {
      "epoch_61": {
        "loss": 1.3916022777557373,
        "accuracy": 0.72802734375
      },
      "epoch_62": {
        "loss": 1.4578863382339478,
        "accuracy": 0.6578369140625
      },
      "epoch_63": {
        "loss": 1.5589498281478882,
        "accuracy": 0.6469929814338684
      },
      "epoch_64": {
        "loss": 1.581861138343811,
        "accuracy": 0.64581298828125
      },
      "epoch_65": {
        "loss": 1.4580858945846558,
        "accuracy": 0.6631672978401184
      },
      "epoch_66": {
        "loss": 1.5323957204818726,
        "accuracy": 0.6466064453125
      },
      "epoch_67": {
        "loss": 1.4381073713302612,
        "accuracy": 0.6656901240348816
      },
      "epoch_68": {
        "loss": 1.3809233903884888,
        "accuracy": 0.6808674931526184
      },
      "epoch_69": {
        "loss": 1.4155211448669434,
        "accuracy": 0.6745808720588684
      },
      "epoch_70": {
        "loss": 1.4180494546890259,
        "accuracy": 0.67083740234375
      },
      "epoch_71": {
        "loss": 1.3090167045593262,
        "accuracy": 0.6892903447151184
      },
      "epoch_72": {
        "loss": 1.3512059450149536,
        "accuracy": 0.6878865361213684
      },
      "epoch_73": {
        "loss": 1.2756720781326294,
        "accuracy": 0.6987507939338684
      },
      "epoch_74": {
        "loss": 1.2624213695526123,
        "accuracy": 0.70416259765625
      },
      "epoch_75": {
        "loss": 1.2560768127441406,
        "accuracy": 0.7085978388786316
      },
      "epoch_76": {
        "loss": 1.2433544397354126,
        "accuracy": 0.71380615234375
      },
      "epoch_77": {
        "loss": 1.1883338689804077,
        "accuracy": 0.71942138671875
      },
      "epoch_78": {
        "loss": 1.2240206003189087,
        "accuracy": 0.7188923954963684
      },
      "epoch_79": {
        "loss": 1.1302729845046997,
        "accuracy": 0.7346598505973816
      },
      "epoch_80": {
        "loss": 1.1071912050247192,
        "accuracy": 0.7404378056526184
      },
      "epoch_81": {
        "loss": 1.2447494268417358,
        "accuracy": 0.750732421875
      },
      "epoch_82": {
        "loss": 0.9994456171989441,
        "accuracy": 0.7614949345588684
      },
      "epoch_83": {
        "loss": 0.9952877163887024,
        "accuracy": 0.76580810546875
      },
      "epoch_84": {
        "loss": 0.9891667366027832,
        "accuracy": 0.76715087890625
      },
      "epoch_85": {
        "loss": 0.9787444472312927,
        "accuracy": 0.76904296875
      },
      "epoch_86": {
        "loss": 0.9746320247650146,
        "accuracy": 0.7731119990348816
      },
      "epoch_87": {
        "loss": 0.9731345772743225,
        "accuracy": 0.7726643681526184
      },
      "epoch_88": {
        "loss": 0.9682044982910156,
        "accuracy": 0.7743123173713684
      },
      "epoch_89": {
        "loss": 0.9685155749320984,
        "accuracy": 0.77423095703125
      },
      "epoch_90": {
        "loss": 0.9715672135353088,
        "accuracy": 0.77447509765625
      }
    },
    "train": {
      "epoch_62": {
        "loss_step": 2.3410398960113525,
        "learning_rate": 0.28568142652511597,
        "loss_epoch": 2.30127215385437,
        "accuracy": 0.6348055601119995,
        "loss": 2.30127215385437
      },
      "epoch_63": {
        "loss_step": 2.344637393951416,
        "learning_rate": 0.2708470821380615,
        "loss_epoch": 2.287980079650879,
        "accuracy": 0.637251615524292,
        "loss": 2.287980079650879
      },
      "epoch_64": {
        "loss_step": 2.3187968730926514,
        "learning_rate": 0.2559625208377838,
        "loss_epoch": 2.2709693908691406,
        "accuracy": 0.6404442191123962,
        "loss": 2.2709693908691406
      },
      "epoch_65": {
        "loss_step": 2.2973005771636963,
        "learning_rate": 0.24107810854911804,
        "loss_epoch": 2.2620346546173096,
        "accuracy": 0.6435539126396179,
        "loss": 2.2620346546173096
      },
      "epoch_66": {
        "loss_step": 2.3128662109375,
        "learning_rate": 0.2262442260980606,
        "loss_epoch": 2.247349977493286,
        "accuracy": 0.6463067531585693,
        "loss": 2.247349977493286
      },
      "epoch_67": {
        "loss_step": 2.303124189376831,
        "learning_rate": 0.21151107549667358,
        "loss_epoch": 2.23832368850708,
        "accuracy": 0.6495048403739929,
        "loss": 2.23832368850708
      },
      "epoch_68": {
        "loss_step": 2.16874098777771,
        "learning_rate": 0.1969284862279892,
        "loss_epoch": 2.221292495727539,
        "accuracy": 0.6528163552284241,
        "loss": 2.221292495727539
      },
      "epoch_69": {
        "loss_step": 2.2264182567596436,
        "learning_rate": 0.18254582583904266,
        "loss_epoch": 2.1979849338531494,
        "accuracy": 0.6571937203407288,
        "loss": 2.1979849338531494
      },
      "epoch_70": {
        "loss_step": 2.1516175270080566,
        "learning_rate": 0.1684117317199707,
        "loss_epoch": 2.187028646469116,
        "accuracy": 0.6617517471313477,
        "loss": 2.187028646469116
      },
      "epoch_71": {
        "loss_step": 2.096757411956787,
        "learning_rate": 0.15457405149936676,
        "loss_epoch": 2.1576263904571533,
        "accuracy": 0.6656736731529236,
        "loss": 2.1576263904571533
      },
      "epoch_72": {
        "loss_step": 2.2277140617370605,
        "learning_rate": 0.1410795897245407,
        "loss_epoch": 2.14225697517395,
        "accuracy": 0.6715369820594788,
        "loss": 2.14225697517395
      },
      "epoch_73": {
        "loss_step": 2.0714879035949707,
        "learning_rate": 0.1279740184545517,
        "loss_epoch": 2.119793653488159,
        "accuracy": 0.6763861179351807,
        "loss": 2.119793653488159
      },
      "epoch_74": {
        "loss_step": 1.9843024015426636,
        "learning_rate": 0.1153016909956932,
        "loss_epoch": 2.0945985317230225,
        "accuracy": 0.6819778680801392,
        "loss": 2.0945985317230225
      },
      "epoch_75": {
        "loss_step": 2.0103235244750977,
        "learning_rate": 0.10310547053813934,
        "loss_epoch": 2.0736687183380127,
        "accuracy": 0.6879530549049377,
        "loss": 2.0736687183380127
      },
      "epoch_76": {
        "loss_step": 2.0826027393341064,
        "learning_rate": 0.09142663329839706,
        "loss_epoch": 2.0387771129608154,
        "accuracy": 0.6941896080970764,
        "loss": 2.0387771129608154
      },
      "epoch_77": {
        "loss_step": 2.091228723526001,
        "learning_rate": 0.08030468970537186,
        "loss_epoch": 2.021578788757324,
        "accuracy": 0.7002853155136108,
        "loss": 2.021578788757324
      },
      "epoch_78": {
        "loss_step": 2.067781448364258,
        "learning_rate": 0.06977728009223938,
        "loss_epoch": 1.9901447296142578,
        "accuracy": 0.7073786854743958,
        "loss": 1.9901447296142578
      },
      "epoch_79": {
        "loss_step": 1.951552391052246,
        "learning_rate": 0.059880029410123825,
        "loss_epoch": 1.9623682498931885,
        "accuracy": 0.7149775624275208,
        "loss": 1.9623682498931885
      },
      "epoch_80": {
        "loss_step": 2.0074567794799805,
        "learning_rate": 0.05064641684293747,
        "loss_epoch": 1.9254082441329956,
        "accuracy": 0.7219042778015137,
        "loss": 1.9254082441329956
      },
      "epoch_81": {
        "loss_step": 1.7347263097763062,
        "learning_rate": 0.04210769012570381,
        "loss_epoch": 1.8913732767105103,
        "accuracy": 0.7298529148101807,
        "loss": 1.8913732767105103
      },
      "epoch_82": {
        "loss_step": 1.3908500671386719,
        "learning_rate": 0.03429274260997772,
        "loss_epoch": 1.4158629179000854,
        "accuracy": 0.8478909730911255,
        "loss": 1.4158629179000854
      },
      "epoch_83": {
        "loss_step": 1.4323155879974365,
        "learning_rate": 0.027228016406297684,
        "loss_epoch": 1.3601137399673462,
        "accuracy": 0.862579345703125,
        "loss": 1.3601137399673462
      },
      "epoch_84": {
        "loss_step": 1.394942045211792,
        "learning_rate": 0.020937416702508926,
        "loss_epoch": 1.3255393505096436,
        "accuracy": 0.8740164041519165,
        "loss": 1.3255393505096436
      },
      "epoch_85": {
        "loss_step": 1.2967760562896729,
        "learning_rate": 0.015442229807376862,
        "loss_epoch": 1.291010856628418,
        "accuracy": 0.8841607570648193,
        "loss": 1.291010856628418
      },
      "epoch_86": {
        "loss_step": 1.257130742073059,
        "learning_rate": 0.010761048644781113,
        "loss_epoch": 1.260708212852478,
        "accuracy": 0.8923050165176392,
        "loss": 1.260708212852478
      },
      "epoch_87": {
        "loss_step": 1.2025161981582642,
        "learning_rate": 0.00690971314907074,
        "loss_epoch": 1.246062994003296,
        "accuracy": 0.899428129196167,
        "loss": 1.246062994003296
      },
      "epoch_88": {
        "loss_step": 1.1626372337341309,
        "learning_rate": 0.0039012550842016935,
        "loss_epoch": 1.2202162742614746,
        "accuracy": 0.9040480256080627,
        "loss": 1.2202162742614746
      },
      "epoch_89": {
        "loss_step": 1.1851553916931152,
        "learning_rate": 0.0017458540387451649,
        "loss_epoch": 1.2115453481674194,
        "accuracy": 0.9073588252067566,
        "loss": 1.2115453481674194
      },
      "epoch_90": {
        "loss_step": 1.221794843673706,
        "learning_rate": 0.00045080314157530665,
        "loss_epoch": 1.2129883766174316,
        "accuracy": 0.9088463187217712,
        "loss": 1.2129883766174316
      }
    }
  },
  "raw_history": [
    {
      "epoch": 61,
      "stage": "val",
      "metrics": {
        "loss": 1.3916022777557373,
        "accuracy": 0.72802734375
      },
      "timestamp": "2025-11-02T00:55:35.718625"
    },
    {
      "epoch": 62,
      "stage": "val",
      "metrics": {
        "loss": 1.4578863382339478,
        "accuracy": 0.6578369140625
      },
      "timestamp": "2025-11-02T01:00:08.069985"
    },
    {
      "epoch": 62,
      "stage": "train",
      "metrics": {
        "loss_step": 2.3410398960113525,
        "learning_rate": 0.28568142652511597,
        "loss_epoch": 2.30127215385437,
        "accuracy": 0.6348055601119995,
        "loss": 2.30127215385437
      },
      "timestamp": "2025-11-02T01:00:08.657525"
    },
    {
      "epoch": 63,
      "stage": "val",
      "metrics": {
        "loss": 1.5589498281478882,
        "accuracy": 0.6469929814338684
      },
      "timestamp": "2025-11-02T01:04:45.630843"
    },
    {
      "epoch": 63,
      "stage": "train",
      "metrics": {
        "loss_step": 2.344637393951416,
        "learning_rate": 0.2708470821380615,
        "loss_epoch": 2.287980079650879,
        "accuracy": 0.637251615524292,
        "loss": 2.287980079650879
      },
      "timestamp": "2025-11-02T01:04:46.293362"
    },
    {
      "epoch": 64,
      "stage": "val",
      "metrics": {
        "loss": 1.581861138343811,
        "accuracy": 0.64581298828125
      },
      "timestamp": "2025-11-02T01:09:24.485831"
    },
    {
      "epoch": 64,
      "stage": "train",
      "metrics": {
        "loss_step": 2.3187968730926514,
        "learning_rate": 0.2559625208377838,
        "loss_epoch": 2.2709693908691406,
        "accuracy": 0.6404442191123962,
        "loss": 2.2709693908691406
      },
      "timestamp": "2025-11-02T01:09:25.054818"
    },
    {
      "epoch": 65,
      "stage": "val",
      "metrics": {
        "loss": 1.4580858945846558,
        "accuracy": 0.6631672978401184
      },
      "timestamp": "2025-11-02T01:14:07.903435"
    },
    {
      "epoch": 65,
      "stage": "train",
      "metrics": {
        "loss_step": 2.2973005771636963,
        "learning_rate": 0.24107810854911804,
        "loss_epoch": 2.2620346546173096,
        "accuracy": 0.6435539126396179,
        "loss": 2.2620346546173096
      },
      "timestamp": "2025-11-02T01:14:08.548323"
    },
    {
      "epoch": 66,
      "stage": "val",
      "metrics": {
        "loss": 1.5323957204818726,
        "accuracy": 0.6466064453125
      },
      "timestamp": "2025-11-02T01:18:49.511732"
    },
    {
      "epoch": 66,
      "stage": "train",
      "metrics": {
        "loss_step": 2.3128662109375,
        "learning_rate": 0.2262442260980606,
        "loss_epoch": 2.247349977493286,
        "accuracy": 0.6463067531585693,
        "loss": 2.247349977493286
      },
      "timestamp": "2025-11-02T01:18:50.118474"
    },
    {
      "epoch": 67,
      "stage": "val",
      "metrics": {
        "loss": 1.4381073713302612,
        "accuracy": 0.6656901240348816
      },
      "timestamp": "2025-11-02T01:23:28.009554"
    },
    {
      "epoch": 67,
      "stage": "train",
      "metrics": {
        "loss_step": 2.303124189376831,
        "learning_rate": 0.21151107549667358,
        "loss_epoch": 2.23832368850708,
        "accuracy": 0.6495048403739929,
        "loss": 2.23832368850708
      },
      "timestamp": "2025-11-02T01:23:28.645432"
    },
    {
      "epoch": 68,
      "stage": "val",
      "metrics": {
        "loss": 1.3809233903884888,
        "accuracy": 0.6808674931526184
      },
      "timestamp": "2025-11-02T01:28:09.221066"
    },
    {
      "epoch": 68,
      "stage": "train",
      "metrics": {
        "loss_step": 2.16874098777771,
        "learning_rate": 0.1969284862279892,
        "loss_epoch": 2.221292495727539,
        "accuracy": 0.6528163552284241,
        "loss": 2.221292495727539
      },
      "timestamp": "2025-11-02T01:28:09.792069"
    },
    {
      "epoch": 69,
      "stage": "val",
      "metrics": {
        "loss": 1.4155211448669434,
        "accuracy": 0.6745808720588684
      },
      "timestamp": "2025-11-02T01:32:48.584088"
    },
    {
      "epoch": 69,
      "stage": "train",
      "metrics": {
        "loss_step": 2.2264182567596436,
        "learning_rate": 0.18254582583904266,
        "loss_epoch": 2.1979849338531494,
        "accuracy": 0.6571937203407288,
        "loss": 2.1979849338531494
      },
      "timestamp": "2025-11-02T01:32:49.251652"
    },
    {
      "epoch": 70,
      "stage": "val",
      "metrics": {
        "loss": 1.4180494546890259,
        "accuracy": 0.67083740234375
      },
      "timestamp": "2025-11-02T01:37:26.245011"
    },
    {
      "epoch": 70,
      "stage": "train",
      "metrics": {
        "loss_step": 2.1516175270080566,
        "learning_rate": 0.1684117317199707,
        "loss_epoch": 2.187028646469116,
        "accuracy": 0.6617517471313477,
        "loss": 2.187028646469116
      },
      "timestamp": "2025-11-02T01:37:26.834963"
    },
    {
      "epoch": 71,
      "stage": "val",
      "metrics": {
        "loss": 1.3090167045593262,
        "accuracy": 0.6892903447151184
      },
      "timestamp": "2025-11-02T01:42:04.308698"
    },
    {
      "epoch": 71,
      "stage": "train",
      "metrics": {
        "loss_step": 2.096757411956787,
        "learning_rate": 0.15457405149936676,
        "loss_epoch": 2.1576263904571533,
        "accuracy": 0.6656736731529236,
        "loss": 2.1576263904571533
      },
      "timestamp": "2025-11-02T01:42:04.971104"
    },
    {
      "epoch": 72,
      "stage": "val",
      "metrics": {
        "loss": 1.3512059450149536,
        "accuracy": 0.6878865361213684
      },
      "timestamp": "2025-11-02T01:46:45.146189"
    },
    {
      "epoch": 72,
      "stage": "train",
      "metrics": {
        "loss_step": 2.2277140617370605,
        "learning_rate": 0.1410795897245407,
        "loss_epoch": 2.14225697517395,
        "accuracy": 0.6715369820594788,
        "loss": 2.14225697517395
      },
      "timestamp": "2025-11-02T01:46:45.634402"
    },
    {
      "epoch": 73,
      "stage": "val",
      "metrics": {
        "loss": 1.2756720781326294,
        "accuracy": 0.6987507939338684
      },
      "timestamp": "2025-11-02T01:51:22.709153"
    },
    {
      "epoch": 73,
      "stage": "train",
      "metrics": {
        "loss_step": 2.0714879035949707,
        "learning_rate": 0.1279740184545517,
        "loss_epoch": 2.119793653488159,
        "accuracy": 0.6763861179351807,
        "loss": 2.119793653488159
      },
      "timestamp": "2025-11-02T01:51:23.329173"
    },
    {
      "epoch": 74,
      "stage": "val",
      "metrics": {
        "loss": 1.2624213695526123,
        "accuracy": 0.70416259765625
      },
      "timestamp": "2025-11-02T01:56:02.170161"
    },
    {
      "epoch": 74,
      "stage": "train",
      "metrics": {
        "loss_step": 1.9843024015426636,
        "learning_rate": 0.1153016909956932,
        "loss_epoch": 2.0945985317230225,
        "accuracy": 0.6819778680801392,
        "loss": 2.0945985317230225
      },
      "timestamp": "2025-11-02T01:56:02.747062"
    },
    {
      "epoch": 75,
      "stage": "val",
      "metrics": {
        "loss": 1.2560768127441406,
        "accuracy": 0.7085978388786316
      },
      "timestamp": "2025-11-02T02:00:43.790255"
    },
    {
      "epoch": 75,
      "stage": "train",
      "metrics": {
        "loss_step": 2.0103235244750977,
        "learning_rate": 0.10310547053813934,
        "loss_epoch": 2.0736687183380127,
        "accuracy": 0.6879530549049377,
        "loss": 2.0736687183380127
      },
      "timestamp": "2025-11-02T02:00:44.437478"
    },
    {
      "epoch": 76,
      "stage": "val",
      "metrics": {
        "loss": 1.2433544397354126,
        "accuracy": 0.71380615234375
      },
      "timestamp": "2025-11-02T02:05:25.041722"
    },
    {
      "epoch": 76,
      "stage": "train",
      "metrics": {
        "loss_step": 2.0826027393341064,
        "learning_rate": 0.09142663329839706,
        "loss_epoch": 2.0387771129608154,
        "accuracy": 0.6941896080970764,
        "loss": 2.0387771129608154
      },
      "timestamp": "2025-11-02T02:05:25.558280"
    },
    {
      "epoch": 77,
      "stage": "val",
      "metrics": {
        "loss": 1.1883338689804077,
        "accuracy": 0.71942138671875
      },
      "timestamp": "2025-11-02T02:10:05.528174"
    },
    {
      "epoch": 77,
      "stage": "train",
      "metrics": {
        "loss_step": 2.091228723526001,
        "learning_rate": 0.08030468970537186,
        "loss_epoch": 2.021578788757324,
        "accuracy": 0.7002853155136108,
        "loss": 2.021578788757324
      },
      "timestamp": "2025-11-02T02:10:06.087143"
    },
    {
      "epoch": 78,
      "stage": "val",
      "metrics": {
        "loss": 1.2240206003189087,
        "accuracy": 0.7188923954963684
      },
      "timestamp": "2025-11-02T02:14:46.780645"
    },
    {
      "epoch": 78,
      "stage": "train",
      "metrics": {
        "loss_step": 2.067781448364258,
        "learning_rate": 0.06977728009223938,
        "loss_epoch": 1.9901447296142578,
        "accuracy": 0.7073786854743958,
        "loss": 1.9901447296142578
      },
      "timestamp": "2025-11-02T02:14:47.498227"
    },
    {
      "epoch": 79,
      "stage": "val",
      "metrics": {
        "loss": 1.1302729845046997,
        "accuracy": 0.7346598505973816
      },
      "timestamp": "2025-11-02T02:19:27.390304"
    },
    {
      "epoch": 79,
      "stage": "train",
      "metrics": {
        "loss_step": 1.951552391052246,
        "learning_rate": 0.059880029410123825,
        "loss_epoch": 1.9623682498931885,
        "accuracy": 0.7149775624275208,
        "loss": 1.9623682498931885
      },
      "timestamp": "2025-11-02T02:19:28.020369"
    },
    {
      "epoch": 80,
      "stage": "val",
      "metrics": {
        "loss": 1.1071912050247192,
        "accuracy": 0.7404378056526184
      },
      "timestamp": "2025-11-02T02:24:09.320126"
    },
    {
      "epoch": 80,
      "stage": "train",
      "metrics": {
        "loss_step": 2.0074567794799805,
        "learning_rate": 0.05064641684293747,
        "loss_epoch": 1.9254082441329956,
        "accuracy": 0.7219042778015137,
        "loss": 1.9254082441329956
      },
      "timestamp": "2025-11-02T02:24:09.918826"
    },
    {
      "epoch": 81,
      "stage": "val",
      "metrics": {
        "loss": 1.2447494268417358,
        "accuracy": 0.750732421875
      },
      "timestamp": "2025-11-02T02:28:52.832642"
    },
    {
      "epoch": 81,
      "stage": "train",
      "metrics": {
        "loss_step": 1.7347263097763062,
        "learning_rate": 0.04210769012570381,
        "loss_epoch": 1.8913732767105103,
        "accuracy": 0.7298529148101807,
        "loss": 1.8913732767105103
      },
      "timestamp": "2025-11-02T02:28:53.427175"
    },
    {
      "epoch": 82,
      "stage": "val",
      "metrics": {
        "loss": 0.9994456171989441,
        "accuracy": 0.7614949345588684
      },
      "timestamp": "2025-11-02T02:32:54.753994"
    },
    {
      "epoch": 82,
      "stage": "train",
      "metrics": {
        "loss_step": 1.3908500671386719,
        "learning_rate": 0.03429274260997772,
        "loss_epoch": 1.4158629179000854,
        "accuracy": 0.8478909730911255,
        "loss": 1.4158629179000854
      },
      "timestamp": "2025-11-02T02:32:55.311227"
    },
    {
      "epoch": 83,
      "stage": "val",
      "metrics": {
        "loss": 0.9952877163887024,
        "accuracy": 0.76580810546875
      },
      "timestamp": "2025-11-02T02:36:57.176581"
    },
    {
      "epoch": 83,
      "stage": "train",
      "metrics": {
        "loss_step": 1.4323155879974365,
        "learning_rate": 0.027228016406297684,
        "loss_epoch": 1.3601137399673462,
        "accuracy": 0.862579345703125,
        "loss": 1.3601137399673462
      },
      "timestamp": "2025-11-02T02:36:57.774285"
    },
    {
      "epoch": 84,
      "stage": "val",
      "metrics": {
        "loss": 0.9891667366027832,
        "accuracy": 0.76715087890625
      },
      "timestamp": "2025-11-02T02:40:59.551207"
    },
    {
      "epoch": 84,
      "stage": "train",
      "metrics": {
        "loss_step": 1.394942045211792,
        "learning_rate": 0.020937416702508926,
        "loss_epoch": 1.3255393505096436,
        "accuracy": 0.8740164041519165,
        "loss": 1.3255393505096436
      },
      "timestamp": "2025-11-02T02:41:00.112434"
    },
    {
      "epoch": 85,
      "stage": "val",
      "metrics": {
        "loss": 0.9787444472312927,
        "accuracy": 0.76904296875
      },
      "timestamp": "2025-11-02T02:45:04.304436"
    },
    {
      "epoch": 85,
      "stage": "train",
      "metrics": {
        "loss_step": 1.2967760562896729,
        "learning_rate": 0.015442229807376862,
        "loss_epoch": 1.291010856628418,
        "accuracy": 0.8841607570648193,
        "loss": 1.291010856628418
      },
      "timestamp": "2025-11-02T02:45:04.799654"
    },
    {
      "epoch": 86,
      "stage": "val",
      "metrics": {
        "loss": 0.9746320247650146,
        "accuracy": 0.7731119990348816
      },
      "timestamp": "2025-11-02T02:49:04.529891"
    },
    {
      "epoch": 86,
      "stage": "train",
      "metrics": {
        "loss_step": 1.257130742073059,
        "learning_rate": 0.010761048644781113,
        "loss_epoch": 1.260708212852478,
        "accuracy": 0.8923050165176392,
        "loss": 1.260708212852478
      },
      "timestamp": "2025-11-02T02:49:05.177206"
    },
    {
      "epoch": 87,
      "stage": "val",
      "metrics": {
        "loss": 0.9731345772743225,
        "accuracy": 0.7726643681526184
      },
      "timestamp": "2025-11-02T02:53:04.419191"
    },
    {
      "epoch": 87,
      "stage": "train",
      "metrics": {
        "loss_step": 1.2025161981582642,
        "learning_rate": 0.00690971314907074,
        "loss_epoch": 1.246062994003296,
        "accuracy": 0.899428129196167,
        "loss": 1.246062994003296
      },
      "timestamp": "2025-11-02T02:53:04.982061"
    },
    {
      "epoch": 88,
      "stage": "val",
      "metrics": {
        "loss": 0.9682044982910156,
        "accuracy": 0.7743123173713684
      },
      "timestamp": "2025-11-02T02:57:02.987110"
    },
    {
      "epoch": 88,
      "stage": "train",
      "metrics": {
        "loss_step": 1.1626372337341309,
        "learning_rate": 0.0039012550842016935,
        "loss_epoch": 1.2202162742614746,
        "accuracy": 0.9040480256080627,
        "loss": 1.2202162742614746
      },
      "timestamp": "2025-11-02T02:57:03.529379"
    },
    {
      "epoch": 89,
      "stage": "val",
      "metrics": {
        "loss": 0.9685155749320984,
        "accuracy": 0.77423095703125
      },
      "timestamp": "2025-11-02T03:01:05.939057"
    },
    {
      "epoch": 89,
      "stage": "train",
      "metrics": {
        "loss_step": 1.1851553916931152,
        "learning_rate": 0.0017458540387451649,
        "loss_epoch": 1.2115453481674194,
        "accuracy": 0.9073588252067566,
        "loss": 1.2115453481674194
      },
      "timestamp": "2025-11-02T03:01:06.494614"
    },
    {
      "epoch": 90,
      "stage": "val",
      "metrics": {
        "loss": 0.9715672135353088,
        "accuracy": 0.77447509765625
      },
      "timestamp": "2025-11-02T03:05:11.061536"
    },
    {
      "epoch": 90,
      "stage": "train",
      "metrics": {
        "loss_step": 1.221794843673706,
        "learning_rate": 0.00045080314157530665,
        "loss_epoch": 1.2129883766174316,
        "accuracy": 0.9088463187217712,
        "loss": 1.2129883766174316
      },
      "timestamp": "2025-11-02T03:05:11.701644"
    }
  ]
}